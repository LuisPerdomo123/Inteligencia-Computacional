{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3s3H2OYNyqF4zPtPxwtST",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisPerdomo123/Inteligencia-Computacional/blob/main/Classiification_MLP_Caso_Practico_III.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptrón Multicapa: Caso práctico III\n",
        "\n",
        "## Dataset\n",
        "te conjunto de datos contine los dicursos de estos líderes prominentes: Benjamín Netányahu, Jens Stolterberg, Julia Gillard, Margaret Tacher y Nelson Mandela que también representa los nombres de las carpetas. Cada audio de la carpeta es un PCM de un segundo de duración con una velicidad de muestreo de 16000 Hz codificado. Una carpeta llamada background_noise contiene los audios que no son discursos, pero que se pueden encontrar en el interior alrededor del enterno del orador, por ejemplo, la audiencia riendo o aplaudiendo. Se puede mezclar con el discurso mientras se entrena."
      ],
      "metadata": {
        "id": "ggUzL2F4WIax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Referencias\n",
        "\n",
        "https://www.kaggle.com/kongaevans/speaker-recognition-dataset/"
      ],
      "metadata": {
        "id": "sXmgXefTXIAd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enunciado\n",
        "El objetivo del ejercicio consiste en utililzar un perceptrón multicapa para la identificación de la persona que se encuentra hablando a partir de un audio de un segundo de duración."
      ],
      "metadata": {
        "id": "ztNKyB_IXY14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Si tienes un dataset comprimido en formato .zip que has cargado en Google Colab, puedes extraerlo y luego acceder a los archivos dentro del dataset. Aquí tienes los pasos para hacerlo:\n",
        "\n",
        "Sube el archivo .zip a Colab: Puedes subir el archivo .zip a Colab utilizando la interfaz de usuario o mediante código. Esto mostrará un botón de \"Seleccionar archivos\" que te permitirá cargar \"16000_pcm_speeches.zip\" desde tu sistema local.\n",
        "\n",
        "Por ejemplo, si el archivo se llama \"16000_pcm_speeches.zip\" y está en tu sistema local, puedes subirlo así:"
      ],
      "metadata": {
        "id": "nHAw-Y1iYV7v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "qadQ9rjzWBT3",
        "outputId": "8f5eaa34-02c8-4727-83f1-16c7c6dcea73"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-52f1c556-0a7d-401e-89b6-43dd8b51d488\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-52f1c556-0a7d-401e-89b6-43dd8b51d488\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 16000_pcm_speeches.zip to 16000_pcm_speeches.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extrae el archivo .zip: Una vez que hayas subido el archivo .zip, este código extraerá el contenido del archivo \"dataset.zip\" en el directorio \"/content/dataset/\" de Colab. Puedes cambiar la ruta de extracción según sea necesario.\n",
        "\n",
        "puedes extraerlo usando el siguiente código:"
      ],
      "metadata": {
        "id": "bvEPQ6uUYbb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('16000_pcm_speeches.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')"
      ],
      "metadata": {
        "id": "jCzHgjS_Yh6C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accede a los archivos del dataset: Ahora que el dataset está descomprimido en el entorno de Colab, puedes acceder a sus archivos normalmente utilizando la ruta donde se extrajo el dataset.\n",
        "\n",
        "Por ejemplo, si dentro del dataset hay un archivo llamado \"archivo.txt\", puedes acceder a él así:"
      ],
      "metadata": {
        "id": "UsNcZMByYknf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos un conjunto de constantes con las rutas de las carpetas que contienen los audios de cada persona\n",
        "import os\n",
        "\n",
        "DATASET_ROOT = \"/content/dataset/16000_pcm_speeches\"\n",
        "BENJAMIN_DATA = os.path.join(DATASET_ROOT, \"Benjamin_Netanyau\")\n",
        "JENS_DATA = os.path.join(DATASET_ROOT, \"Jens_Stoltenberg\")\n",
        "JULIA_DATA = os.path.join(DATASET_ROOT, \"Julia_Gillard\")\n",
        "MARGARET_DATA = os.path.join(DATASET_ROOT, \"Margaret_Tarcher\")\n",
        "NELSON_DATA = os.path.join(DATASET_ROOT, \"Nelson_Mandela\")"
      ],
      "metadata": {
        "id": "0eauIbQPYhSN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparación del conjunto de datos"
      ],
      "metadata": {
        "id": "v88LqRcOel9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos una función para parsear nuestro conjunto de datos\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def parse_dataset(dataset_paths):\n",
        "  X = []\n",
        "  y = []\n",
        "  for index, dataset in enumerate(dataset_paths):\n",
        "    print(\"[+] Parsing {} data...\".format(dataset))\n",
        "    for fname in os.listdir(dataset):\n",
        "      wav, sr = librosa.load(os.path.join(dataset, fname), sr=None)\n",
        "      D = librosa.amplitude_to_db(np.abs(librosa.stft(wav)), ref=np.max)\n",
        "      X.append(D)\n",
        "      y.append(index)\n",
        "  return (X, y)"
      ],
      "metadata": {
        "id": "4L2DtRL_epec"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = parse_dataset([BENJAMIN_DATA, JENS_DATA, JULIA_DATA, NELSON_DATA])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9U3ifCLfy8H",
        "outputId": "0e24ddab-798e-46e9-aeaa-c0d206e4e301"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[+] Parsing /content/dataset/16000_pcm_speeches/Benjamin_Netanyau data...\n",
            "[+] Parsing /content/dataset/16000_pcm_speeches/Jens_Stoltenberg data...\n",
            "[+] Parsing /content/dataset/16000_pcm_speeches/Julia_Gillard data...\n",
            "[+] Parsing /content/dataset/16000_pcm_speeches/Nelson_Mandela data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. División del conjunto de datos"
      ],
      "metadata": {
        "id": "eeS4s7TliIo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
      ],
      "metadata": {
        "id": "Pix8dtyOgB1m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test, X_val, y_tets, y_val = train_test_split(X_test, y_test, test_size=0.5)"
      ],
      "metadata": {
        "id": "dVP45DbvijW0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Longitud subconjunto de entrenamiento: \", len(X_train))\n",
        "print(\"Longitud subconjunto de validación: \", len(X_val))\n",
        "print(\"Longitud subconjunto de pruebas: \", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWHz66Mxi10L",
        "outputId": "dad9b3c5-7c73-4ebf-976b-2497cc472420"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longitud subconjunto de entrenamiento:  5400\n",
            "Longitud subconjunto de validación:  301\n",
            "Longitud subconjunto de pruebas:  300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Construcción del modelo"
      ],
      "metadata": {
        "id": "J9xgn74HiIU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def prep_dataset(X, y, shape):\n",
        "  X_prep = np.array(X).reshape(len(X), shape)\n",
        "  X_prep = X_prep.astype('float32') / 255\n",
        "  y_prep = to_categorical(np.array(y))\n",
        "  return (X_prep, y_prep)"
      ],
      "metadata": {
        "id": "7v19ONxDjPBx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_prep, y_train_prep = prep_dataset(X_train, y_train, 1025*32)\n",
        "X_val_prep, y_val_prep = prep_dataset(X_val, y_val, 1025*32)\n",
        "X_test_prep, y_test_prep = prep_dataset(X_test, y_test, 1025*32)"
      ],
      "metadata": {
        "id": "plRXfwDMkHYL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_prep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIIjvoIplVC9",
        "outputId": "81dcac8c-1b40-4964-8c1b-b80f08a2a158"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.2856507 , -0.1980031 , -0.17526971, ..., -0.3137255 ,\n",
              "        -0.29284686, -0.25467676],\n",
              "       [-0.14373729, -0.1709079 , -0.22460534, ..., -0.2689801 ,\n",
              "        -0.22339493, -0.19149806],\n",
              "       [-0.17463434, -0.13898051, -0.13941142, ..., -0.3137255 ,\n",
              "        -0.2938944 , -0.26547614],\n",
              "       ...,\n",
              "       [-0.28978968, -0.29095238, -0.3137255 , ..., -0.3137255 ,\n",
              "        -0.29578316, -0.2560798 ],\n",
              "       [-0.21726583, -0.20812435, -0.19313487, ..., -0.3137255 ,\n",
              "        -0.2805897 , -0.2444185 ],\n",
              "       [-0.1539024 , -0.18409081, -0.20397244, ..., -0.3137255 ,\n",
              "        -0.3137255 , -0.28312832]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_prep"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq4GKyY_lXPd",
        "outputId": "21683088-4e2f-4509-9cd3-e815666c2fc7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1. Entrenamiento de una RNA sencilla"
      ],
      "metadata": {
        "id": "EV9a_GUilcTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos un perceptrón multicapa\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "clf = MLPClassifier(activation='logistic', hidden_layer_sizes=(10,), solver='sgd')\n",
        "clf.fit(X_train_prep, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "YrVeG598lZkQ",
        "outputId": "85a5ee37-397f-402c-9369-86890a14bbef"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', hidden_layer_sizes=(10,), solver='sgd')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(10,), solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;, hidden_layer_sizes=(10,), solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Realizamos la predicción con el conjunto de datos de validación\n",
        "y_pred = clf.predict(X_val_prep)"
      ],
      "metadata": {
        "id": "P2_R1EQOmWI1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostramos el accuracy resultante de la clasificación\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_val,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvM8FoxemgWn",
        "outputId": "c75daf7a-1abd-4f4b-cc95-72fc16708f6b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9534883720930233"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2. Entrenamiento de una RNA profunda"
      ],
      "metadata": {
        "id": "SoFCP66ZnKgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "UFJnNXOamrsd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Entrenamiento de una RNA profunda"
      ],
      "metadata": {
        "id": "nIib2YFrnySF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "iPTnz36XnVsY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network = models.Sequential()\n",
        "\n",
        "network.add(layers.Dense(300, activation='relu', input_shape=(1025*32,)))\n",
        "network.add(layers.Dense(200, activation='relu'))\n",
        "network.add(layers.Dense(100, activation='relu'))\n",
        "network.add(layers.Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "u_YH5t-gn_nq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "network.compile(loss='categorical_crossentropy',\n",
        "                optimizer='sgd',\n",
        "                metrics=['accuracy','Precision'])"
      ],
      "metadata": {
        "id": "yXJQFHSponb5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7w5IzPzLpAH6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}